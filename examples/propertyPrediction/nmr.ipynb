{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "brazilian-marijuana",
   "metadata": {},
   "source": [
    "# This tutorial is for NMR (atom-level properties) training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faced-falls",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dongdongzhang/Desktop/group/databases/EzChem/ez_chem\n"
     ]
    }
   ],
   "source": [
    "cd ../../ez_chem/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-arrival",
   "metadata": {},
   "source": [
    "## Create molecular graphs for NMR datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "documentary-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "from featurization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "italian-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "official-flour",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-thumbnail",
   "metadata": {},
   "source": [
    "Load in original NMR data in form of pickle file, such as for 1H. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "loving-daily",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('../NMRShiftDB/graph_conv_many_nuc_pipeline.data.1H.nmrshiftdb_hconfspcl_nmrshiftdb.aromatic.64.1.mol_dict.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "wired-board",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train_df', 'test_df', 'MAX_N', 'spectra_config', 'tgt_nucs'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "vital-synthesis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1H']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tgt_nucs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "rocky-label",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data['train_df']\n",
    "test_df = data['test_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "objective-bacteria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10252, 4), (2554, 4))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "unsigned-insider",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([train_df[['molecule_id', 'rdmol', 'value']], test_df[['molecule_id', 'rdmol', 'value']]]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "palestinian-premium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12806, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "mature-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "considerable-manitoba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = Chem.MolFromSmiles('C1=CC=CC=C1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "small-christopher",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcIAAACWCAIAAADCEh9HAAAABmJLR0QA/wD/AP+gvaeTAAAX00lEQVR4nO3dfVRUdf4H8C9ICyiQYMjmAyrGDA8hgkIiICsUmSmK+Qg+RKboBjI8CKIYphkBedoePNq6x/aEqatnNW3NZTdFLIVcA8/RZWBQlGdBcGBgGGCYmd8ft9jqZ3ln4M535t736/8v543H8+Fzv997P18LnU5HAADAUJa0AwAAmDeUUQCAIUEZBQAYEpRRAIAhsaIdAMyGXC6vq6ujncJIXF1dHR0daacA84AyCqwUFhYWFRXl5ubSDmIkGRkZc+fOffHFF2kHATNggRee4LFUKpWnp2dtbe2UKVPs7e1px+FcV1fX3bt3J02aJJVKbW1taccBU4duFB4vLy+vtrZ2+vTp169fHzFiBO04nNNqtc8999z169fz8/PffPNN2nHA1KEbhcdobGwUi8VKpfLSpUthYWG04xjJlStXQkNDbWxsKisrXV1daccBk4aTeniM9PR0pVK5fPly4dRQQkhwcPDSpUtVKtX27dtpZwFTh24UfktJSUlwcLCNjU1FRcXkyZNpxzGq+vp6Dw8PlUpVXFwcGhpKOw6YLnSj8Ku0Wq1EItHpdFu3bhVaDSWETJw4MTU1VafTSSQSrVZLOw6YLnSj8KsOHz68fv368ePHV1VVjRo1inYcClQqlYeHR11d3eHDh+Pi4mjHAROFMgqP1tXVJRaLm5ubP//885iYGNpxqPn8889Xr17t4uIik8kcHBxoxwFThId6eLS9e/c2NzcHBQWtWrWKdhaaYmJiQkJCWlpacnJyaGcBE4VuFB6hpqbGy8tLrVaXlJQEBgbSjkNZWVlZQECAlZXVrVu33N3daccBk4NuFB4hJSWlr69v3bp1qKGEEH9//7Vr1/b396enp9POAqYI3Sj80sWLFyMiIuzt7auqqp5++mnacUxCS0uLSCRSKBT//Oc/8aE9/AK6UfgZjUYjkUgIITt27EANHeTi4pKZmUkISUlJUavVtOOAaUEZhZ85cODAzZs33dzcmGIKg1JSUtzd3SsqKv785z/TzgKmBQ/18D9yuVwkErW1tX3xxReLFi0y4Cdcvny5rKxs2IMNL39//zlz5hiw8IsvvoiOjnZ0dKyurh4zZsywBwNzpQP4UUJCAiEkPDzc4J+QnJxM+3/04yUnJxv8C0ZGRhJCEhMTDf4JwD/oRuEHFRUV06dP12q15eXlPj4+hv2QM2fOFBUVDW+wYTd37lzDem1CSEVFha+vr06nG8q/EvAMyij8YN68eYWFhQkJCR999BHtLCYtISFh//794eHhFy5coJ0FTALKKBBCyJkzZxYvXuzo6CiTyZ566inacUyaXC53d3dvb28/c+ZMVFQU7ThAH07qgQy+WL57927U0MdydHTMzs4mP36kQDsO0IcyCuT999+XyWSenp7x8fG0s5iHzZs3+/j43Llz54MPPqCdBejDQ73QtbS0iMXizs5OfJ+jlwsXLjz//PP41gsIulHIzMzs7OxctGgRaqheIiIioqKiurq6srKyaGcBytCNClp5efnMmTOtrKxu3rwpEoloxzEzd+7c8fb2VqvVpaWlAQEBtOMANehGhUun0yUlJTE3haCGGmDq1KlbtmzRarVJSUloR4QM3ahwHT16NDY2duzYsTKZ7Mknn6QdxywN3hFw9OhRgc+3FjJ0owI1eHVwTk4OaqjB7O3t9+zZQ368hpp2HKADZVSg3n333draWj8/v1dffZV2FvMWFxcXEBDQ0NCQn59POwvQgYd6IWpoaBCLxbiBfbiUlJQEBwfb2NhIpdJJkybRjgPGhm5UiNLS0np6elauXIkaOiyCgoJWrFihUqm2bdtGOwtQgG5UcK5evRoSEoLWaXg1NDR4eHgolcri4mLDhpmC+UI3KiyDb+dkZGSghg6jCRMmpKWlEUIkEolGo6EdB4wK3aiwHDp0aOPGjRMmTKisrBw1ahTtOLyiUqk8PT1ra2sPHTr0+uuv044DxoMyKiBdXV0ikej+/fvHjx9fsWIF7Tg8dPz48VWrVuFVXKHBQ72A7N69+/79+7Nnz16+fDntLPy0cuXKOXPmtLa27t27l3YWMB50o0KBD8CNA2MKBAjdqFBIJJK+vr7XXnsNNZRTfn5+cXFx/f39zIkTCAG6UUH4+uuvX3jhBQzHNI7W1laRSNTZ2Xn+/Pl58+bRjgOcQzfKfwMDA8y9x2+++SZqqBGMHTt2x44dhJCUlBS1Wk07DnAOZZT/9u/ff+vWralTpyYmJtLOIhRJSUkikUgqlR44cIB2FuAcHup57uHDhyKRqL29/csvv1ywYAHtOALy5ZdfRkVF4bJVIUA3ynNZWVnt7e0RERGooUa2cOHCefPmyeVy5hpR4DF0o3z23//+d/r06YSQ8vLyZ599lnYcwZFKpb6+vlqttqysbNq0abTjAFfQjfJZcnLywMDAG2+8gRpKhaen5+bNmzUajUQioZ0FOIRulLdOnTr1yiuvODk5yWSyMWPG0I4jUHK5XCQStbW1nTp1Kjo6mnYc4AS6UX7q7+9nZl++/fbbqKEUOTo6vvXWW4SQtLS03t5e2nGAEyij/PTee+9VV1d7eXlt2LCBdhahi4+PnzZtWk1Nzfvvv087C3ACD/U81NLSIhKJFApFYWFhZGQk7ThALl68GBERYWdnV1VVNW7cONpxYJihG+Wh9PR0hUKxZMkS1FATER4eHh0d3d3dzdzGCjyDbpRvvv/++8DAQCsrq1u3brm7u9OOAz+oqanx9vbu6+srLS0NDAykHQeGE7pRXtHpdBKJRKvVpqamooaaFDc3N4lEotPpmEtcaMeB4YRulFcKCgrWrl3r4uIik8kcHBxox4Gf6e7uFovFTU1NBQUFq1evph0Hhg26Uf7o6enJysoihOTm5qKGmiA7OztmKv62bdu6u7tpx4FhgzLKH++8805dXd2MGTPWrFlDOws82rp16wIDAxsbG3Nzc2lngWGDh3qeqK+v9/DwUKlUly9fDgkJoR0HflVpaens2bOtra2lUunkyZNpx4FhgG6UJ1JSUnp6emJjY1FDTdysWbNiYmJ6e3vT09NpZ4HhgW6UD7799ts5c+bY2tpKpVJXV1faceAxGhsbxWKxUqksKir6wx/+QDsODBW6UbOn1WqZN2kyMzNRQ83C+PHjMzIyCCESiUSj0dCOA0OFbtTsHTx4cPPmzRMnTqysrBw5ciTtOMBKb2+vp6fnvXv3Dh48GB8fTzsODAnKqHlTKBQikailpeXkyZNLly6lHQf0cPLkyeXLlzs7O8tkstGjR9OOA4bDQ71527VrV0tLS3Bw8CuvvEI7C+hn2bJlYWFhDx482LNnD+0sMCToRs1YZWXltGnTNBrNtWvXZsyYQTsO6O3GjRszZ860sLC4ceOGt7c37ThgIHSjZoy5Bn3Dhg2ooWZq+vTp69evHxgYSE5Opp0FDIdu1FydO3duwYIFDg4OVVVVv//972nHAQM9ePBAJBJ1dHScO3du/vz5tOOAIdCNmiW1Wp2amkoI2bVrF2qoWXN2dt65cychJCkpqb+/n3YcMATKqFn66KOPqqqqnnnmmTfeeIN2FhiqxMREsVh8+/bt/fv3084ChsBDvfnBYyD/YIvGrKEbNT/FxcXd3d1hYWGoobzx8ssvh4WF9fT0fPvtt7SzgN5QRgEAhgRl1PyEh4c7ODgUFxefO3fOgOU4x+CUYf+8//jHP4qLi+3s7MLCwoY9EnANZdT8ODk5MVPuJRJJX18f+4U6nS4vL2/KlClNTU2cpRO0pqamKVOm5OXl6XXkoFar09LSCCHZ2dnOzs6cpQOuoIyapcTERG9vb33Pdi0sLEpLS5uamnDNL0cyMzObmpq+++47CwsL9qs+/PDDqqoqDw8PvHdhpnBSb67+/e9/R0ZG6nu2O3jNb0lJyXPPPcdpQqEx7Grr1tZWsVjc0dHx1VdfvfTSS5wmBI6gGzVXL7zwwvz58xUKRXZ2NvtVbm5uycnJzD3M+As6jJibk7VabVpaml5XW2dlZXV0dLz88suooWZMB2arurra2tra0tLyP//5D/tVXV1d48aNI4QUFBRwl01oPvvsM0KIi4tLZ2cn+1Xl5eUjRox44oknKisrucsGXEM3asaYr5gGp9+zXGVnZ/fOO+8QXPM7fAavts7Ly9Pramtm+v2WLVvEYjFn6YB7tOs4DElnZyezMXrixAn2q7RabWBgICEkKyuLu2zCsWPHDkLIjBkzNBoN+1V/+9vfCCHOzs5yuZy7bGAEKKNm7+DBg4SQiRMnKpVK9qtKSkosLCxsbGxqamq4yyYEtbW1I0eOtLCw+Oabb9iv6unpYW5X/uSTT7jLBsaBh3qzx8wbra+v37dvH/tVs2bNio2NxTW/Q8dcbb169Wq9rrbOz8+/d+8eM2+Uu2xgHHjhiQ+uXLkSGhpqY2NTWVnJ/nLQxsZGDw+P7u5uXPNrMMOuth68YPnSpUv4bIkH0I3yQXBw8NKlS1UqlV7v1Q9e85uQkDAwMMBZOt7SaDQJCQk6nW779u16XW2dnp6uVCqXL1+OGsoTtHcVYHjU1dUZsEOnUqmYHbqDBw9yl42vDhw4QPTflb569SqzK3337l3OooFRoYzyB/POjb+/v17nxSdOnCCEODk5tbe3c5eNf+RyOfP9+8mTJ9mv0mg0zDsSO3fu5C4bGBnKKH8olUrm0fLTTz/VayGzMcp83QQsSSQSQkhISIhWq2W/6vDhw4SQ8ePHd3d3c5cNjAxllFcKCgqI/t/S3LhxY8SIEczH4Nxl4xOpVPrEE09YWlpev36d/SqFQvH0008TQo4cOcJdNjA+HDHxSmxsbEhISEtLS05ODvtVvr6+uOZXL4Zdbb13797m5uagoKCYmBjusoHx4YUnvikrKwsICNB3zhDud2LPsHuTBmdrlZaWMtujwBvoRvnG399/zZo1/f39zMtMLP30ml+9RkELjcFXW6empvb29q5btw41lIdo7yrA8Lt//z4zIKOwsJD9qv7+fmZAxr59+7jLZu7ee+89QsgzzzzT19fHftWFCxcIIXZ2do2NjdxlA1pQRvmJmeHk5eWlVqvZr/rXv/5FCHFwcGhubuYum/lqbW0dPXo0IeSrr75iv2pgYMDHx4cQkpOTw102oAhllJ/6+vqYjdH9+/frtZAZHhwfH89RMLO2ceNGQsj8+fP1WvXxxx8TQtzc3FQqFUfBgC4cMfHW6dOnlyxZ4uTkJJPJxowZw3LV7du3vb29BwYGrl27ptcxNO/duHFj5syZlpaWN2/eZD8eVC6Xi0Sitra206dPL168mNOEQAuOmHgrOjo6MjLy4cOHu3fvZr9qcBR0UlIS/sT+FDNiOTExUa8Ry9nZ2W1tbeHh4aihPIZulM8qKip8fX0JIWVlZcz2HBsKhUIsFt+/f//EiRPLli3jMqDZOHHixIoVK5ydnWUyGbM9yoZUKvX19dVqtWVlZdOmTeM0IVCEbpTPvLy8Nm7cqO979Q4ODrt27SKEpKam9vT0cBXOfPT29jJvj7399tvsayghJDk5Wa1Wb9q0CTWU5yjvzQLH2tvbmY3Rs2fPsl+l0WiYjdE9e/Zwl81cMLsivr6+AwMD7FedOXOGEOLo6PjgwQPusoEpQBnlvw8++IAQMnXq1N7eXvarvvnmGwsLi5EjR9bW1nKXzfQ1NDSMGjWKEFJUVMR+VV9fn0gkIoR8+OGHnEUDU4Eyyn9qtfrZZ58lhOTl5em1cOnSpYSQ1atXcxTMLMTGxhJCli1bpteq3NxcQoinp2d/fz9HwcB04IhJEC5cuPD888/b29tXVVUxQ4bYqK+v9/DwUKlUly9f1uuiId4oKSkJDg62traWSqXMfGs2WltbRSJRZ2fn+fPn582bx2VAMAk4YhKEiIiIhQsXdnV1MR/OszRx4sSUlBSdTpeUlKTVarmLZ5p0Op1EItHpdFu3bmVfQwkhmZmZnZ2dUVFRqKFCQbcZBqO5ffu2tbW1paXltWvX2K8aHAX917/+lbtspunTTz8l+o9YLisrs7S0/N3vfldVVcVdNjApKKMCsnXrVkJIUFCQXgPbP/vsM6L/KGhz19XVNW7cOEJIQUGBXgtDQ0MJIenp6RwFAxOEMiogg9PXjx07xn6VVqtlNkYzMzO5y2Zqtm3bRgiZNWuWXn9yjh49SggZO3ZsR0cHd9nA1KCMCsuhQ4cIIRMmTNDrQfX69evMg6pMJuMum+m4c+eOjY2NhYXFd999x35VT0/PpEmTCCF/+ctfuMsGJghHTMLy2muvBQQENDQ05Ofns181Y8YMA0ZBmy/DRizn5ubW1tb6+fnFxcVxlw1MEF54EpyrV6+GhITY2NhIpVKme2KjpaVFJBIpFIrCwsLIyEhOE9J18eLFiIgIOzu7qqoqZnuUjYaGBg8PD6VSWVxcPGfOHE4TgqlBNyo4s2fPXrFihUqlYrb/WHJxcWFa0eTk5IGBAc7SUabRaJj5A9u3b2dfQwkhaWlpSqVy1apVqKFCRHtXASior69nPnAsLi5mv8rgUdBmxLARy1euXLGwsLC1tb137x532cBkoYwKVHZ2NiHEz89Po9GwX/X3v/+dEOLk5NTW1sZdNloePnz41FNPEUJOnTrFfpVGowkICCCEZGdncxYNTBrKqEAZfKzMbIxu2bKFo2AUJSYmEkLCw8P1WmXYyw/AJzhiEq5jx47FxMSMHTtWJpM9+eSTLFcNjoIuLy9nJp7wg2Ejlru6usRicXNz87Fjx1auXMlpQjBZOGISLuY8pLW1de/evexXeXl5bdiwYWBgQCKRcJfN+FJSUtRqdXx8vF4jlnfv3t3c3Myc2nGXDUwculFBKy8vnzlzppWV1c2bN5n5mGw8fPhQJBK1t7efPXt24cKFnCY0jrNnzy5atMjR0VEmkzHbo2zcuXPH29tbrVaXlpYy26MgTOhGBc3Pz+/VV1/t7+9nPrdnycnJiZkUlZyc3NfXx1k6Ixn89Xft2sW+hpIff/24uDjUUKGjvTkLlLW0tDAbo+fPn2e/anAUdH5+PnfZjCMvL4/oP2L566+/JoTY29s3NTVxlw3MAsooGDiqnR91ZIh/RfS9UAB4CWUUDL84aMGCBYSQ119/naNgRrB+/XpCyMKFC/VaZdj1VsBXOGICQgw9Y5HJZD4+Pg4ODtXV1XrdPGwiOjo63N3dFQqFwE/YYIhwxASEEBIVFfXiiy/K5XLmhnqWRCLR8ePHKysrzbGGEkJGjx5dWVl5/Phx9jWUELJz58729nbmXhbusoEZQTcKPzDs/XOhGfz6oKyszMfHh3YcMAnoRuEHnp6emzZtGhxxBI/EDLj64x//iBoKg9CNwv/I5XKRSNTW1nb69OnFixfTjmNyTp8+vWTJEicnJ5lMNmbMGNpxwFSgG4X/cXR0ZPZGmfHvtOOYlsHh/3v27EENhZ9CGYWf2bRpk4+PT01NzZ/+9CfaWUzLvn37qqurvby8Nm7cSDsLmBY81MMvGXaLBr8J5w4VMAC6Ufil8PDwxYsXd3d379ixg3YWU5GRkaFQKKKjo1FD4f9DNwqPUFNT4+3t3dfXV1paqtftmLz0/fffBwYGWllZ3bp1i7lGBeCn0I3CI7i5uUkkEp1Ol5SUJPA/tDqdTiKRaLXa1NRU1FB4JHSj8Gjd3d0ikai5ufnIkSOxsbG041Bz5MiRNWvWuLi4yGQyBwcH2nHAFKEbhUezs7NjpuJnZGQolUracejo6elhNojfffdd1FD4NSij8KvWrVsXGBjY2NjITNIToJycnLq6On9//7Vr19LOAqYLD/XwW0pKSoKDg62traVS6eTJk2nHMar6+noPDw+VSnX58uWQkBDaccB0oRuF3xIUFBQTE9Pb25uenk47i7GlpKT09PTExsaihsJvQzcKj9HY2CgWi5VK5aVLl8LCwmjHMZIrV66Ehoba2NhUVla6urrSjgMmDd0oPMb48eOZVlQikWg0GtpxjEGr1TJvemVmZqKGwmOhG4XHU6lUnp6etbW1U6ZMsbe3px2Hc11dXXfv3p00aZJUKrW1taUdB0ydFe0AYAZsbW0/+eSToqIi4RzZZ2RkzJ07FzUU2EA3CmzJ5fK6ujraKYzE1dXV0dGRdgowDyijAABDgiMmAIAhQRkFABgSlFEAgCFBGQUAGJL/A/zsHD8tDhMEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x7fe6a6e80580>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "curious-avatar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 0\n"
     ]
    }
   ],
   "source": [
    "for bond in mol.GetBonds():\n",
    "    print(bond.GetBeginAtomIdx(), bond.GetEndAtomIdx())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "similar-illness",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genGraphs(all_data, id_, smilesColumn, targetColumn, MAX_N=64):\n",
    "    examples = []\n",
    "    for idx, smi, tar in tqdm(zip(all_data[id_].tolist(), all_data[smilesColumn].tolist(), all_data[targetColumn].tolist())):\n",
    "        #print(idx)\n",
    "        molgraphs = {}\n",
    "        at_begin, at_end = [], []\n",
    "        atom_feature_list = []\n",
    "        bond_feature_list = []\n",
    "\n",
    "        #mol_graph = MolGraph(smi, '1-GNN')\n",
    "        \n",
    "        for atom in smi.GetAtoms():\n",
    "            atom_feature_list.append(atom_features(atom))\n",
    "        for bond in smi.GetBonds():\n",
    "            bond_feature_list.append(bond_features_new(bond))\n",
    "            bond_feature_list.append(bond_features_new(bond))\n",
    "            at_begin.append(bond.GetBeginAtom().GetIdx())\n",
    "            at_begin.append(bond.GetEndAtom().GetIdx())\n",
    "            at_end.append(bond.GetEndAtom().GetIdx())\n",
    "            at_end.append(bond.GetBeginAtom().GetIdx())\n",
    "        \n",
    "        molgraphs['x'] = torch.FloatTensor(atom_feature_list) # atom features \n",
    "        molgraphs['edge_attr'] = torch.FloatTensor(bond_feature_list) # bond features \n",
    "        molgraphs['edge_index'] = torch.LongTensor(np.concatenate([at_begin, at_end]).reshape(2,-1))\n",
    "        \n",
    "        molgraphs['smiles'] = smi\n",
    "        molgraphs['id'] = torch.FloatTensor([idx])\n",
    "        \n",
    "        mask = np.zeros((molgraphs['x'].shape[0], 1), dtype=np.float32)\n",
    "        vals = np.zeros((molgraphs['x'].shape[0], 1), dtype=np.float32)\n",
    "        for k, v in tar[0].items():\n",
    "            mask[int(k), 0] = 1.0\n",
    "            vals[int(k), 0] = v\n",
    "        molgraphs['y'] = torch.FloatTensor(vals).flatten()\n",
    "        molgraphs['mask'] = torch.FloatTensor(mask).flatten()\n",
    "        examples.append(molgraphs)\n",
    "        \n",
    "        #if idx % 100 == 0:\n",
    "        #print('Finish processing {} compounds'.format(idx))\n",
    "    print('Done.')\n",
    "        \n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "proprietary-welsh",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12806it [00:44, 288.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "graphs = genGraphs(all_df, 'molecule_id', 'rdmol', 'value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "following-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(graphs, '../examples/propertyPrediction/nmr/hydrogen/raw/temp.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-affect",
   "metadata": {},
   "source": [
    "## Create data loader for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "stunning-theorem",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "artificial-spokesman",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'dataset': 'nmr/carbon', # dataset name\n",
    "          'model': '1-GNN',  # model \n",
    "          'train_type': 'from_scratch', \n",
    "          'normalize': False,\n",
    "          'train_size': 1000, \n",
    "          'val_size': 123, \n",
    "          'batch_size': 16,\n",
    "          'data_path': '../examples/propertyPrediction/nmr/hydrogen/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "random-fence",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = get_data_loader(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sorted-option",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(loader.train_loader.dataset)), print(len(loader.val_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-timber",
   "metadata": {},
   "source": [
    "## Prepare models for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "colored-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dirty-romance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import *\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "medium-tribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_train = {'num_layer': 3, # atom embedding layers \n",
    "                'emb_dim':64, # embedding dimension\n",
    "                'NumOutLayers': 3, # number of read-out layers\n",
    "                'num_tasks':1, \n",
    "                'pooling': 'sum',\n",
    "                'gnn_type': 'nnconv', \n",
    "                'optimizer': 'adam',\n",
    "                'lr': 0.001,\n",
    "                'loss': 'maskedL2',\n",
    "                'metrics': 'l1', \n",
    "                'drop_ratio': 0.,\n",
    "                'JK': 'last',\n",
    "                'weights': 'xavier_norm', # weights initialization method \n",
    "                'taskType': 'single',\n",
    "                'propertyLevel': 'atom',\n",
    "                'EFGS': False,\n",
    "                'solvent':'',\n",
    "                'interaction': '',\n",
    "                'device': torch.device('cpu')\n",
    "                \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "configured-terrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.update(config_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "hydraulic-fleece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': 'nmr/carbon',\n",
       " 'model': '1-GNN',\n",
       " 'train_type': 'from_scratch',\n",
       " 'normalize': False,\n",
       " 'train_size': 1000,\n",
       " 'val_size': 123,\n",
       " 'batch_size': 16,\n",
       " 'data_path': '../examples/propertyPrediction/nmr/hydrogen/',\n",
       " 'num_layer': 3,\n",
       " 'emb_dim': 64,\n",
       " 'num_readout_layers': 3,\n",
       " 'num_tasks': 1,\n",
       " 'graph_pooling': 'sum',\n",
       " 'gnn_type': 'nnconv',\n",
       " 'optimizer': 'adam',\n",
       " 'lr': 0.001,\n",
       " 'loss': 'maskedL2',\n",
       " 'metrics': 'l1',\n",
       " 'drop_ratio': 0.0,\n",
       " 'JK': 'last',\n",
       " 'weights': 'xavier_norm',\n",
       " 'taskType': 'single',\n",
       " 'propertyLevel': 'atom',\n",
       " 'EFGS': False,\n",
       " 'solvent': '',\n",
       " 'interaction': '',\n",
       " 'device': device(type='cpu'),\n",
       " 'NumOutLayers': 3,\n",
       " 'pooling': 'sum'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "active-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "analyzed-diabetes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNN_1(\n",
       "  (gnn): GNN(\n",
       "    (x_embedding1): Sequential(\n",
       "      (0): Linear(in_features=40, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (gnns): ModuleList(\n",
       "      (0): NNCon(\n",
       "        (edge_embedding1): Embedding(6, 64)\n",
       "        (edge_embedding2): Embedding(4, 64)\n",
       "        (conv_): NNConv(64, 64)\n",
       "      )\n",
       "      (1): NNCon(\n",
       "        (edge_embedding1): Embedding(6, 64)\n",
       "        (edge_embedding2): Embedding(4, 64)\n",
       "        (conv_): NNConv(64, 64)\n",
       "      )\n",
       "      (2): NNCon(\n",
       "        (edge_embedding1): Embedding(6, 64)\n",
       "        (edge_embedding2): Embedding(4, 64)\n",
       "        (conv_): NNConv(64, 64)\n",
       "      )\n",
       "    )\n",
       "    (batch_norms): ModuleList(\n",
       "      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (outLayers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=8, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (4): Linear(in_features=8, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(config['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cooperative-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_weights(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "numerical-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "neural-basket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss is 2.2709293365478516 and val error is 0.9689146677652994 and val error is 0.9244341966582508 at epoch 1\n",
      "Train loss is 0.7832245230674744 and val error is 0.6122402422355883 and val error is 0.6669253837771532 at epoch 2\n",
      "Train loss is 0.6145329475402832 and val error is 0.6224354252670751 and val error is 0.684511603378668 at epoch 3\n",
      "Train loss is 0.48110538721084595 and val error is 0.6762602257006096 and val error is 0.8071994316287157 at epoch 4\n",
      "Train loss is 0.6878549456596375 and val error is 0.6279304966782079 and val error is 0.6736039882752953 at epoch 5\n",
      "Train loss is 1.2578308582305908 and val error is 0.5878243301853989 and val error is 0.6403601111435309 at epoch 6\n",
      "Train loss is 0.8931701183319092 and val error is 0.6096532995050604 and val error is 0.6427620213206221 at epoch 7\n",
      "Train loss is 0.5441385507583618 and val error is 0.6626265554717092 and val error is 0.691843405002501 at epoch 8\n",
      "Train loss is 1.6684919595718384 and val error is 0.6510038086862275 and val error is 0.6669097993432022 at epoch 9\n",
      "Train loss is 0.5163070559501648 and val error is 0.755891973322088 and val error is 0.7883321250357279 at epoch 10\n",
      "Train loss is 1.579993486404419 and val error is 0.6024665254535098 and val error is 0.6258863123451791 at epoch 11\n",
      "Train loss is 0.8844240307807922 and val error is 0.5913749463630446 and val error is 0.6217732778409633 at epoch 12\n",
      "Train loss is 0.9404630661010742 and val error is 0.558266899802468 and val error is 0.6275340754811357 at epoch 13\n",
      "Train loss is 1.1825470924377441 and val error is 0.6435010505445076 and val error is 0.6986094218928639 at epoch 14\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-35fb0c5e455c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m#print(loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#val_error = 0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/group/databases/EzChem/ez_chem/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, dataloader, config)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;31m#sys.stdout.flush()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 100):\n",
    "    loss = train(model, optimizer, loader.train_loader, config)\n",
    "    #print(loss)\n",
    "    train_error = test(model, loader.train_loader, config)\n",
    "    #val_error = 0.\n",
    "    val_error = test(model, loader.val_loader, config)\n",
    "    #test_error = test(model, loader.test_loader, config)\n",
    "    #test_error = 0.\n",
    "    print(\"Train loss is {} and val error is {} and val error is {} at epoch {}\".format(loss, train_error, val_error, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-relevance",
   "metadata": {},
   "outputs": [],
   "source": [
    "Chem.MolF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
